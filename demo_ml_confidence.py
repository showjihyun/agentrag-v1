#!/usr/bin/env python3
"""
ML ì‹ ë¢°ë„ ì˜ˆì¸¡ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ ì‚¬ìš© ì˜ˆì œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import sys
import os

# ë°±ì—”ë“œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

from ml.confidence_predictor import MLConfidencePredictor, ConfidenceFeatures
from services.confidence_service import ConfidenceService


def print_section(title):
    """ì„¹ì…˜ ì œëª© ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def demo_basic_prediction():
    """ê¸°ë³¸ ì˜ˆì¸¡ ë°ëª¨"""
    print_section("1. ê¸°ë³¸ ì‹ ë¢°ë„ ì˜ˆì¸¡")
    
    predictor = MLConfidencePredictor()
    
    # ê³ í’ˆì§ˆ íŠ¹ì§•
    high_quality = ConfidenceFeatures(
        query_length=15,
        query_complexity=0.7,
        has_keywords=True,
        num_sources=5,
        avg_similarity_score=0.9,
        max_similarity_score=0.95,
        source_diversity=0.8,
        response_length=300,
        has_citations=True,
        reasoning_steps=4,
        mode='deep',
        has_memory_context=True,
        cache_hit=True,
        user_feedback_history=0.9,
        similar_query_success_rate=0.85
    )
    
    confidence = predictor.predict(high_quality)
    print(f"\nâœ… ê³ í’ˆì§ˆ ì¿¼ë¦¬ ì‹ ë¢°ë„: {confidence:.2%}")
    print(f"   - ë§ì€ ì†ŒìŠ¤ (5ê°œ)")
    print(f"   - ë†’ì€ ìœ ì‚¬ë„ (0.9)")
    print(f"   - Deep ëª¨ë“œ")
    print(f"   - ìºì‹œ íˆíŠ¸")
    
    # ì €í’ˆì§ˆ íŠ¹ì§•
    low_quality = ConfidenceFeatures(
        query_length=3,
        query_complexity=0.2,
        has_keywords=False,
        num_sources=0,
        avg_similarity_score=0.3,
        max_similarity_score=0.3,
        source_diversity=0.0,
        response_length=20,
        has_citations=False,
        reasoning_steps=0,
        mode='fast',
        has_memory_context=False,
        cache_hit=False,
        user_feedback_history=0.3,
        similar_query_success_rate=0.4
    )
    
    confidence = predictor.predict(low_quality)
    print(f"\nâŒ ì €í’ˆì§ˆ ì¿¼ë¦¬ ì‹ ë¢°ë„: {confidence:.2%}")
    print(f"   - ì†ŒìŠ¤ ì—†ìŒ (0ê°œ)")
    print(f"   - ë‚®ì€ ìœ ì‚¬ë„ (0.3)")
    print(f"   - Fast ëª¨ë“œ")
    print(f"   - ìºì‹œ ë¯¸ìŠ¤")


def demo_uncertainty():
    """ë¶ˆí™•ì‹¤ì„± ì¶”ì • ë°ëª¨"""
    print_section("2. ë¶ˆí™•ì‹¤ì„± ì¶”ì •")
    
    predictor = MLConfidencePredictor()
    
    # ë¶ˆí™•ì‹¤í•œ ì¼€ì´ìŠ¤
    uncertain = ConfidenceFeatures(
        query_length=10,
        query_complexity=0.5,
        has_keywords=True,
        num_sources=1,  # ì ì€ ì†ŒìŠ¤
        avg_similarity_score=0.4,  # ë‚®ì€ ìœ ì‚¬ë„
        max_similarity_score=0.5,
        source_diversity=0.3,
        response_length=100,
        has_citations=False,
        reasoning_steps=1,
        mode='fast',
        has_memory_context=False,
        cache_hit=False,
        user_feedback_history=0.0,  # íˆìŠ¤í† ë¦¬ ì—†ìŒ
        similar_query_success_rate=0.5
    )
    
    confidence, uncertainty = predictor.predict_with_uncertainty(uncertain)
    print(f"\nâš ï¸  ë¶ˆí™•ì‹¤í•œ ì¼€ì´ìŠ¤:")
    print(f"   ì‹ ë¢°ë„: {confidence:.2%}")
    print(f"   ë¶ˆí™•ì‹¤ì„±: {uncertainty:.2%}")
    
    if uncertainty > 0.2:
        print(f"\n   â†’ ë†’ì€ ë¶ˆí™•ì‹¤ì„±! íœ´ë¦¬ìŠ¤í‹±ê³¼ ë¸”ë Œë”© ê¶Œì¥")
    else:
        print(f"\n   â†’ ë‚®ì€ ë¶ˆí™•ì‹¤ì„±, ML ì˜ˆì¸¡ ì‚¬ìš© ê°€ëŠ¥")


def demo_service_integration():
    """ì„œë¹„ìŠ¤ í†µí•© ë°ëª¨"""
    print_section("3. ConfidenceService ì‚¬ìš©")
    
    service = ConfidenceService(use_ml=True)
    
    # ì‹¤ì œ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    result = service.calculate_confidence(
        query="What is machine learning and how does it work?",
        sources=[
            {'score': 0.92, 'document_id': 'doc1', 'cited': True},
            {'score': 0.88, 'document_id': 'doc2', 'cited': True},
            {'score': 0.75, 'document_id': 'doc3', 'cited': False}
        ],
        response="Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It works by using algorithms to analyze data, identify patterns, and make decisions.",
        mode='balanced',
        reasoning_steps=3,
        has_memory=True,
        cache_hit=False
    )
    
    print(f"\nğŸ“Š ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼:")
    print(f"   ì‹ ë¢°ë„: {result['confidence']:.2%}")
    print(f"   ë°©ë²•: {result['method']}")
    
    if 'uncertainty' in result:
        print(f"   ë¶ˆí™•ì‹¤ì„±: {result['uncertainty']:.2%}")
    
    if 'ml_score' in result and 'heuristic_score' in result:
        print(f"\n   ML ì ìˆ˜: {result['ml_score']:.2%}")
        print(f"   íœ´ë¦¬ìŠ¤í‹± ì ìˆ˜: {result['heuristic_score']:.2%}")
        print(f"   â†’ ë¸”ë Œë”© ì‚¬ìš©ë¨")


def demo_feedback_learning():
    """í”¼ë“œë°± í•™ìŠµ ë°ëª¨"""
    print_section("4. í”¼ë“œë°± í•™ìŠµ")
    
    service = ConfidenceService(use_ml=True)
    predictor = service.ml_predictor
    
    print(f"\ní˜„ì¬ í•™ìŠµ ë°ì´í„°: {len(predictor.training_data)}ê°œ")
    
    # í”¼ë“œë°± ì‹œë®¬ë ˆì´ì…˜
    print("\ní”¼ë“œë°± ê¸°ë¡ ì¤‘...")
    for i in range(5):
        service.record_feedback(
            query=f"Test query {i}",
            sources=[{'score': 0.8, 'document_id': f'doc{i}'}],
            response=f"Test response {i}",
            mode='balanced',
            actual_feedback=0.7 + (i * 0.05),  # 0.7 ~ 0.9
            reasoning_steps=2,
            has_memory=False,
            cache_hit=False
        )
        print(f"   âœ“ í”¼ë“œë°± {i+1}/5 ê¸°ë¡ë¨")
    
    print(f"\nì—…ë°ì´íŠ¸ëœ í•™ìŠµ ë°ì´í„°: {len(predictor.training_data)}ê°œ")
    print(f"\nğŸ’¡ 100ê°œ ì´ìƒ ìˆ˜ì§‘ ì‹œ ìë™ í•™ìŠµë©ë‹ˆë‹¤.")


def demo_low_quality_improvement():
    """ì €í’ˆì§ˆ ì¿¼ë¦¬ ê°œì„  ë°ëª¨"""
    print_section("5. ì €í’ˆì§ˆ ì¿¼ë¦¬ ê°œì„  (NEW!)")
    
    service = ConfidenceService(use_ml=False)  # íœ´ë¦¬ìŠ¤í‹±ë§Œ ì‚¬ìš©
    
    # ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ì§€ì‹ ì¿¼ë¦¬ (ì†ŒìŠ¤ ì—†ìŒ)
    print("\nğŸ“š ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë°˜ ì§€ì‹ ì¿¼ë¦¬")
    result1 = service.calculate_confidence(
        query="What is machine learning?",  # ì¼ë°˜ ì§€ì‹ ì¿¼ë¦¬
        sources=[],  # ì†ŒìŠ¤ ì—†ìŒ
        response="Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It uses algorithms to analyze data, identify patterns, and make decisions with minimal human intervention.",
        mode='balanced',
        reasoning_steps=2
    )
    print(f"   ì¿¼ë¦¬: 'What is machine learning?'")
    print(f"   ì†ŒìŠ¤: ì—†ìŒ")
    print(f"   ì‹ ë¢°ë„: {result1['confidence']:.2%}")
    print(f"   ë°©ë²•: {result1['method']}")
    if 'llm_baseline' in result1:
        print(f"   LLM ê¸°ë³¸: {result1['llm_baseline']:.2%}")
    if 'response_quality' in result1:
        print(f"   ì‘ë‹µ í’ˆì§ˆ: {result1['response_quality']:.2%}")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 2: ì§§ì€ ì‘ë‹µ (ì†ŒìŠ¤ ì—†ìŒ)
    print("\nğŸ“ ì‹œë‚˜ë¦¬ì˜¤ 2: ì§§ì€ ì‘ë‹µ")
    result2 = service.calculate_confidence(
        query="Define AI",
        sources=[],
        response="AI is artificial intelligence.",  # ì§§ì€ ì‘ë‹µ
        mode='fast',
        reasoning_steps=0
    )
    print(f"   ì¿¼ë¦¬: 'Define AI'")
    print(f"   ì†ŒìŠ¤: ì—†ìŒ")
    print(f"   ì‘ë‹µ: ì§§ìŒ (5ë‹¨ì–´)")
    print(f"   ì‹ ë¢°ë„: {result2['confidence']:.2%}")
    print(f"   â†’ ìµœì†Œ ì„ê³„ê°’ ì ìš©ë¨")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 3: ê³ í’ˆì§ˆ ì‘ë‹µ (ì†ŒìŠ¤ ì—†ìŒ)
    print("\nâœ¨ ì‹œë‚˜ë¦¬ì˜¤ 3: ê³ í’ˆì§ˆ ì‘ë‹µ")
    result3 = service.calculate_confidence(
        query="Explain how neural networks work",
        sources=[],
        response="""Neural networks are computational models inspired by the human brain. They consist of:

1. Input Layer: Receives the initial data
2. Hidden Layers: Process information through weighted connections
3. Output Layer: Produces the final result

The network learns by adjusting weights through backpropagation, minimizing the difference between predicted and actual outputs. This process enables the network to recognize patterns and make predictions on new data.""",
        mode='deep',
        reasoning_steps=3
    )
    print(f"   ì¿¼ë¦¬: 'Explain how neural networks work'")
    print(f"   ì†ŒìŠ¤: ì—†ìŒ")
    print(f"   ì‘ë‹µ: ê³ í’ˆì§ˆ (êµ¬ì¡°í™”, ê¸´ ê¸¸ì´)")
    print(f"   ì‹ ë¢°ë„: {result3['confidence']:.2%}")
    if 'quality_boost' in result3:
        print(f"   í’ˆì§ˆ ë³´ë„ˆìŠ¤: +{result3['quality_boost']:.2%}")
    
    print("\nğŸ’¡ ê°œì„  íš¨ê³¼:")
    print(f"   - ì¼ë°˜ ì§€ì‹ ì¿¼ë¦¬: {result1['confidence']:.2%} (ì´ì „: ~5%)")
    print(f"   - ì§§ì€ ì‘ë‹µ: {result2['confidence']:.2%} (ìµœì†Œ ì„ê³„ê°’)")
    print(f"   - ê³ í’ˆì§ˆ ì‘ë‹µ: {result3['confidence']:.2%} (í’ˆì§ˆ ë³´ë„ˆìŠ¤)")


def demo_comparison():
    """ML vs íœ´ë¦¬ìŠ¤í‹± ë¹„êµ ë°ëª¨"""
    print_section("6. ML vs íœ´ë¦¬ìŠ¤í‹± ë¹„êµ")
    
    service = ConfidenceService(use_ml=True)
    
    features = ConfidenceFeatures(
        query_length=12,
        query_complexity=0.6,
        has_keywords=True,
        num_sources=4,
        avg_similarity_score=0.85,
        max_similarity_score=0.92,
        source_diversity=0.75,
        response_length=200,
        has_citations=True,
        reasoning_steps=3,
        mode='balanced',
        has_memory_context=True,
        cache_hit=False,
        user_feedback_history=0.8,
        similar_query_success_rate=0.82
    )
    
    heuristic = service._calculate_heuristic_confidence(features)
    ml_score = service.ml_predictor.predict(features)
    
    print(f"\nğŸ“Š ë™ì¼í•œ íŠ¹ì§•ì— ëŒ€í•œ ë¹„êµ:")
    print(f"   íœ´ë¦¬ìŠ¤í‹± ë°©ì‹: {heuristic:.2%}")
    print(f"   ML ë°©ì‹: {ml_score:.2%}")
    print(f"   ì°¨ì´: {abs(ml_score - heuristic):.2%}")
    
    if abs(ml_score - heuristic) < 0.1:
        print(f"\n   âœ… ë‘ ë°©ì‹ì´ ìœ ì‚¬í•œ ê²°ê³¼ (ì°¨ì´ < 10%)")
    else:
        print(f"\n   âš ï¸  ë‘ ë°©ì‹ì˜ ì°¨ì´ê°€ í¼ (ì°¨ì´ â‰¥ 10%)")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ¤– ML ì‹ ë¢°ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë°ëª¨".center(60))
    print("=" * 60)
    
    try:
        demo_basic_prediction()
        demo_uncertainty()
        demo_service_integration()
        demo_feedback_learning()
        demo_low_quality_improvement()
        demo_comparison()
        
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  ë°ëª¨ ì™„ë£Œ!".center(60))
        print("=" * 60)
        
        print("\nğŸ“š ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ì‹¤ì œ ì¿¼ë¦¬ì— ì ìš©: backend/api/query.py ì°¸ê³ ")
        print("   2. í”¼ë“œë°± ìˆ˜ì§‘: backend/api/feedback.py ì°¸ê³ ")
        print("   3. ëª¨ë¸ í•™ìŠµ: 100ê°œ ì´ìƒ í”¼ë“œë°± ìˆ˜ì§‘ í›„ ìë™ í•™ìŠµ")
        print("   4. API ì‚¬ìš©: POST /api/confidence/calculate")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
