# ðŸŽ¯ Feature Highlights

## 1. Multi-Agent Architecture

### Aggregator Agent (Master Coordinator)
- **ReAct Pattern**: Reasoning + Acting for systematic problem-solving
- **Chain of Thought**: Step-by-step reasoning process
- **Dynamic Planning**: Adapts strategy based on query complexity
- **Memory Integration**: Leverages STM and LTM for context-aware responses

### Specialized Agents

#### Vector Search Agent
```python
Capabilities:
- Semantic similarity search using Milvus
- Hybrid search (vector + keyword)
- Reranking with cross-encoders
- Source citation tracking
```

#### Local Data Agent
```python
Capabilities:
- File system access
- Database queries
- Structured data retrieval
- Metadata extraction
```

#### Web Search Agent
```python
Capabilities:
- Real-time web search
- Content extraction
- Fact verification
- Source validation
```

## 2. Adaptive Query Routing

### Automatic Complexity Analysis

```python
Query Complexity Factors:
â”œâ”€ Length: Number of words/sentences
â”œâ”€ Structure: Question type, clauses
â”œâ”€ Intent: Information vs. analysis
â”œâ”€ Context: Single vs. multi-document
â””â”€ Reasoning: Simple lookup vs. complex inference

Complexity Score: 0.0 - 1.0
â”œâ”€ 0.0 - 0.35: Fast Mode
â”œâ”€ 0.35 - 0.70: Balanced Mode
â””â”€ 0.70 - 1.0: Deep Mode
```

### Mode Characteristics

| Feature | Fast | Balanced | Deep |
|---------|------|----------|------|
| Response Time | < 1s | < 3s | < 10s |
| Documents Retrieved | 5 | 10 | 15 |
| Agent Iterations | 1-2 | 3-5 | 5-10 |
| Reasoning Depth | Basic | Moderate | Comprehensive |
| Use Cases | Simple Q&A | General queries | Complex analysis |

## 3. Multimodal Document Processing

### Supported Formats

#### Text Documents
- **PDF**: PyPDF2 + opendataloader-pdf for tables
- **DOCX**: python-docx with table extraction
- **TXT/MD**: Direct text processing
- **HWP/HWPX**: Korean Hangul format support

#### Presentations
- **PPTX**: python-pptx with slide extraction
- **PPT**: Legacy format support

#### Spreadsheets
- **XLSX**: openpyxl with formula evaluation
- **XLS**: xlrd for legacy Excel
- **CSV**: pandas integration

#### Images
- **PNG, JPG, GIF, BMP, WEBP**: OCR + ColPali

### Advanced Processing Features

#### Table Extraction
```python
Features:
â”œâ”€ Structure Recognition: Rows, columns, headers
â”œâ”€ Cell Merging: Handles merged cells
â”œâ”€ Formula Evaluation: Calculates Excel formulas
â”œâ”€ Formatting Preservation: Bold, italic, colors
â””â”€ Search Optimization: Key-value format
```

#### Image Understanding (ColPali)
```python
Capabilities:
â”œâ”€ Visual Question Answering
â”œâ”€ Chart/Graph Interpretation
â”œâ”€ Diagram Understanding
â”œâ”€ Text in Images (OCR)
â””â”€ Multimodal Retrieval
```

#### Contextual Retrieval
```python
Enhancement:
â”œâ”€ Document Context: Title, author, date
â”œâ”€ Section Context: Chapter, heading hierarchy
â”œâ”€ Chunk Context: Surrounding paragraphs
â””â”€ Semantic Context: Related concepts
```

## 4. Memory Management

### Short-Term Memory (STM)

```python
Storage: Redis
Purpose: Conversation context
Scope: Session-based
TTL: 1 hour (configurable)

Features:
â”œâ”€ Message History: Last 20 messages
â”œâ”€ User Preferences: Language, mode
â”œâ”€ Session State: Current document, filters
â””â”€ Temporary Cache: Recent queries
```

### Long-Term Memory (LTM)

```python
Storage: Milvus
Purpose: Pattern learning
Scope: User-based
Persistence: Permanent

Features:
â”œâ”€ Query Patterns: Common question types
â”œâ”€ User Preferences: Preferred sources, topics
â”œâ”€ Feedback Learning: Thumbs up/down
â””â”€ Performance Metrics: Response quality
```

## 5. Multi-LLM Support

### Supported Providers

#### Local (Ollama)
```yaml
Models:
  - llama3.1 (8B, 70B)
  - mistral (7B)
  - mixtral (8x7B)
  - codellama (7B, 13B, 34B)
  - phi-2 (2.7B)

Advantages:
  - No API costs
  - Data privacy
  - Low latency
  - Offline capability
```

#### Cloud (OpenAI)
```yaml
Models:
  - gpt-4-turbo
  - gpt-4
  - gpt-3.5-turbo

Advantages:
  - High quality
  - Large context
  - Fast inference
  - Multimodal
```

#### Cloud (Anthropic)
```yaml
Models:
  - claude-3-opus
  - claude-3-sonnet
  - claude-3-haiku

Advantages:
  - Long context (200K)
  - High reasoning
  - Safety features
  - Fast responses
```

### Automatic Fallback

```python
Strategy:
1. Try primary provider
2. If timeout/error â†’ Try fallback #1
3. If still failing â†’ Try fallback #2
4. If all fail â†’ Return error with details

Configuration:
LLM_PROVIDER=ollama
LLM_FALLBACK_PROVIDERS=openai,claude
```

## 6. Real-time Streaming

### Server-Sent Events (SSE)

```typescript
Stream Types:
â”œâ”€ Agent Steps: Reasoning process
â”œâ”€ Document Retrieval: Sources found
â”œâ”€ Partial Responses: Incremental text
â”œâ”€ Citations: Source references
â””â”€ Metadata: Confidence, timing
```

### UI Features

```typescript
Real-time Updates:
â”œâ”€ Typing Animation: Character-by-character
â”œâ”€ Progress Indicators: Current step
â”œâ”€ Source Cards: Live citation display
â”œâ”€ Reasoning Tree: Agent decision flow
â””â”€ Error Handling: Graceful degradation
```

## 7. Performance Optimization

### Caching Strategy

```python
L1 Cache (Redis):
â”œâ”€ TTL: 1 hour
â”œâ”€ Scope: Exact query match
â”œâ”€ Hit Rate: 40-50%
â””â”€ Latency: < 10ms

L2 Cache (Redis):
â”œâ”€ TTL: 24 hours
â”œâ”€ Scope: Semantic similarity
â”œâ”€ Hit Rate: 20-30%
â””â”€ Latency: < 50ms

Total Hit Rate: 60-80%
```

### Parallel Processing

```python
Parallel Execution:
â”œâ”€ Initial Retrieval: Vector + Web + Local (parallel)
â”œâ”€ Agent Coordination: Independent agents run concurrently
â”œâ”€ Document Processing: Batch embedding generation
â””â”€ Reranking: Parallel cross-encoder inference

Speedup: 2-3x faster than sequential
```

### Query Optimization

```python
Techniques:
â”œâ”€ Query Expansion: Synonyms, related terms
â”œâ”€ Query Rewriting: Clarification, simplification
â”œâ”€ Hybrid Search: Vector + keyword combination
â”œâ”€ Reranking: Cross-encoder for precision
â””â”€ Result Deduplication: Remove redundant sources
```

## 8. Korean Language Optimization

### Embedding Models

```python
Primary: jhgan/ko-sroberta-multitask
â”œâ”€ Dimensions: 768
â”œâ”€ Training: Korean-specific corpus
â”œâ”€ Performance: Best for Korean semantic search
â””â”€ Use Case: General Korean documents

Alternative: BM-K/KoSimCSE-roberta
â”œâ”€ Dimensions: 768
â”œâ”€ Training: SimCSE on Korean data
â”œâ”€ Performance: Excellent similarity matching
â””â”€ Use Case: Conversational queries
```

### Reranking Models

```python
Adaptive Selection:
â”œâ”€ Korean-only content â†’ Dongjin-kr/ko-reranker
â”œâ”€ Multilingual content â†’ BAAI/bge-reranker-v2-m3
â””â”€ Auto-detection based on language ratio

Performance:
â”œâ”€ Korean Reranker: 92% accuracy on Korean
â”œâ”€ Multilingual: 88% accuracy on mixed content
â””â”€ Fallback: Cross-encoder/ms-marco-MiniLM
```

### Text Processing

```python
Features:
â”œâ”€ Morpheme Analysis: Korean word segmentation
â”œâ”€ Spacing Normalization: Fix OCR spacing errors
â”œâ”€ Jamo Handling: Korean character decomposition
â”œâ”€ Hanja Conversion: Chinese characters to Hangul
â””â”€ Dialect Support: Regional variations
```

## 9. Security & Privacy

### Authentication

```python
Method: JWT (JSON Web Tokens)
â”œâ”€ Access Token: 24 hours
â”œâ”€ Refresh Token: 7 days
â”œâ”€ Algorithm: HS256
â””â”€ Secure Storage: HttpOnly cookies
```

### Authorization

```python
Levels:
â”œâ”€ User: Own documents only
â”œâ”€ Admin: All documents
â”œâ”€ Guest: Public documents only
â””â”€ API Key: Programmatic access
```

### Data Privacy

```python
Features:
â”œâ”€ User Isolation: Separate vector collections
â”œâ”€ Document Encryption: At rest and in transit
â”œâ”€ Audit Logging: All access tracked
â”œâ”€ GDPR Compliance: Data deletion on request
â””â”€ Local LLM Option: No data leaves premises
```

## 10. Monitoring & Analytics

### Real-time Metrics

```python
Query Metrics:
â”œâ”€ Response Time: P50, P95, P99
â”œâ”€ Mode Distribution: Fast/Balanced/Deep
â”œâ”€ Cache Hit Rate: L1, L2, Total
â”œâ”€ Error Rate: By type and endpoint
â””â”€ Throughput: Queries per second

System Metrics:
â”œâ”€ CPU Usage: Per service
â”œâ”€ Memory Usage: Per service
â”œâ”€ Disk I/O: Read/write rates
â”œâ”€ Network: Bandwidth usage
â””â”€ Database: Connection pool, query time
```

### Analytics Dashboard

```python
Visualizations:
â”œâ”€ Query Volume: Time series
â”œâ”€ Response Time: Histogram
â”œâ”€ Mode Distribution: Pie chart
â”œâ”€ Cache Performance: Line chart
â”œâ”€ Error Trends: Bar chart
â””â”€ User Activity: Heatmap
```

### Auto-tuning

```python
Adaptive Thresholds:
â”œâ”€ Analyze: 1000+ queries
â”œâ”€ Calculate: Optimal complexity thresholds
â”œâ”€ Adjust: Mode boundaries
â”œâ”€ Monitor: Performance impact
â””â”€ Iterate: Continuous improvement

Target Distribution:
â”œâ”€ Fast Mode: 40-50%
â”œâ”€ Balanced Mode: 30-40%
â””â”€ Deep Mode: 20-30%
```

---

## ðŸŽ¯ Use Cases

### 1. Enterprise Knowledge Base
- Internal documentation search
- Policy and procedure lookup
- Employee onboarding
- Compliance verification

### 2. Research & Academia
- Literature review
- Paper summarization
- Citation tracking
- Cross-reference analysis

### 3. Legal & Compliance
- Contract analysis
- Regulatory research
- Case law search
- Due diligence

### 4. Customer Support
- FAQ automation
- Ticket resolution
- Knowledge base search
- Product documentation

### 5. Content Creation
- Research assistance
- Fact checking
- Source citation
- Content summarization

---

**[â† Back to README](../README.md)**
