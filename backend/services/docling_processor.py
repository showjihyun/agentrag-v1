"""
Docling Document Processor

IBM Researchì˜ Doclingì„ ì‚¬ìš©í•œ ê³ ê¸‰ ë¬¸ì„œ ì²˜ë¦¬
- í‘œ/ì°¨íŠ¸ ìë™ ì¶”ì¶œ
- ë ˆì´ì•„ì›ƒ ë¶„ì„
- êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
- ColPali í†µí•©
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import json
import asyncio

logger = logging.getLogger(__name__)


class DoclingProcessor:
    """
    Docling ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ê¸°
    
    Features:
    - PDF/DOCX/PPTX ì§€ì›
    - í‘œ êµ¬ì¡° ì¶”ì¶œ
    - ì°¨íŠ¸/ê·¸ë¦¼ ê°ì§€
    - ë ˆì´ì•„ì›ƒ ë¶„ì„
    - OCR í†µí•©
    - ColPali ì—°ë™
    """
    
    def __init__(
        self,
        enable_ocr: bool = True,
        enable_table_structure: bool = True,
        enable_figure_extraction: bool = True,
        images_scale: float = 2.0
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            enable_ocr: OCR í™œì„±í™”
            enable_table_structure: í‘œ êµ¬ì¡° ë¶„ì„
            enable_figure_extraction: ê·¸ë¦¼/ì°¨íŠ¸ ì¶”ì¶œ
            images_scale: ì´ë¯¸ì§€ í•´ìƒë„ ë°°ìœ¨
        """
        self.enable_ocr = enable_ocr
        self.enable_table_structure = enable_table_structure
        self.enable_figure_extraction = enable_figure_extraction
        self.images_scale = images_scale
        
        self.converter = None
        
        self._init_docling()
        self._init_colpali()
        
        logger.info(
            f"DoclingProcessor initialized: "
            f"ocr={enable_ocr}, tables={enable_table_structure}, "
            f"figures={enable_figure_extraction}, scale={images_scale}"
        )
    
    def _init_docling(self):
        """Docling ì´ˆê¸°í™”"""
        try:
            from docling.document_converter import DocumentConverter
            
            # Docling 2.xì—ì„œëŠ” ê°„ë‹¨í•œ ì´ˆê¸°í™”ë§Œ í•„ìš”
            # Pipeline ì˜µì…˜ì€ convert() í˜¸ì¶œ ì‹œ ì „ë‹¬
            self.converter = DocumentConverter()
            
            logger.info("âœ… Docling converter initialized")
            logger.info(f"   - OCR: {self.enable_ocr}")
            logger.info(f"   - Table structure: {self.enable_table_structure}")
            logger.info(f"   - Figure extraction: {self.enable_figure_extraction}")
            
        except ImportError as e:
            logger.error(f"âŒ Docling not installed: {e}")
            logger.error("Install with: pip install docling")
            raise
        except Exception as e:
            logger.error(f"âŒ Docling initialization failed: {e}")
            raise
    
    def _init_colpali(self):
        """ColPali removed - not used"""
        try:
            # ColPali initialization removed
            pass
            
            if False:
                logger.info("âœ… ColPali integration enabled")
            else:
                logger.warning("âš ï¸  ColPali not available")
                
        except Exception as e:
            logger.warning(f"âš ï¸  ColPali initialization failed: {e}")
    
    async def process_document(
        self,
        file_path: str,
        document_id: str,
        user_id: str,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ì²˜ë¦¬ (Docling)
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            document_id: ë¬¸ì„œ ID
            user_id: ì‚¬ìš©ì ID
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        
        Returns:
            {
                'document_id': str,
                'user_id': str,
                'text_chunks': List[Dict],  # í…ìŠ¤íŠ¸ ì²­í¬
                'tables': List[Dict],       # ì¶”ì¶œëœ í‘œ
                'figures': List[Dict],      # ì¶”ì¶œëœ ê·¸ë¦¼/ì°¨íŠ¸
                'layout': Dict,             # ë ˆì´ì•„ì›ƒ ì •ë³´
                'metadata': Dict,           # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
                'stats': Dict               # ì²˜ë¦¬ í†µê³„
            }
        """
        try:
            logger.info(f"ğŸš€ Processing document with Docling: {document_id}")
            
            # Docling ë³€í™˜
            result = self.converter.convert(file_path)
            
            # ê²°ê³¼ êµ¬ì¡° ì´ˆê¸°í™”
            processed = {
                'document_id': document_id,
                'user_id': user_id,
                'text_chunks': [],
                'tables': [],
                'figures': [],
                'layout': {},
                'metadata': metadata or {},
                'stats': {}
            }
            
            # 1. í…ìŠ¤íŠ¸ ì²­í¬ ì¶”ì¶œ
            logger.info("ğŸ“ Extracting text chunks...")
            processed['text_chunks'] = self._extract_text_chunks(
                result, document_id, user_id
            )
            
            # 2. í‘œ ì¶”ì¶œ
            logger.info("ğŸ“Š Extracting tables...")
            processed['tables'] = self._extract_tables(
                result, document_id, user_id
            )
            
            # 3. ê·¸ë¦¼/ì°¨íŠ¸ ì¶”ì¶œ
            if self.enable_figure_extraction:
                logger.info("ğŸ–¼ï¸  Extracting figures...")
                processed['figures'] = await self._extract_figures(
                    result, document_id, user_id, file_path
                )
            
            # 4. ë ˆì´ì•„ì›ƒ ì •ë³´
            processed['layout'] = self._extract_layout(result)
            
            # 5. ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
            doc_metadata = self._extract_metadata(result)
            processed['metadata'].update(doc_metadata)
            
            # 6. í†µê³„
            processed['stats'] = {
                'num_text_chunks': len(processed['text_chunks']),
                'num_tables': len(processed['tables']),
                'num_figures': len(processed['figures']),
                'num_pages': processed['layout'].get('num_pages', 0)
            }
            
            logger.info(
                f"âœ… Docling processing complete: "
                f"{processed['stats']['num_text_chunks']} chunks, "
                f"{processed['stats']['num_tables']} tables, "
                f"{processed['stats']['num_figures']} figures"
            )
            
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Docling processing failed: {e}")
            raise
    
    def _extract_text_chunks(
        self,
        result,
        document_id: str,
        user_id: str
    ) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ì²­í¬ ì¶”ì¶œ (ì˜ë¯¸ ë‹¨ìœ„)"""
        chunks = []
        
        try:
            # Docling 2.x: result.document.export_to_markdown() ë˜ëŠ” ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(result, 'document'):
                doc = result.document
                
                # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if hasattr(doc, 'export_to_markdown'):
                    full_text = doc.export_to_markdown()
                elif hasattr(doc, 'export_to_text'):
                    full_text = doc.export_to_text()
                else:
                    full_text = str(doc)
                
                # ê°„ë‹¨í•œ ì²­í‚¹ (ë‹¨ë½ ë‹¨ìœ„)
                paragraphs = [p.strip() for p in full_text.split('\n\n') if p.strip()]
                
                for i, text in enumerate(paragraphs):
                    if len(text) < 10:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                        continue
                    
                    chunks.append({
                        'chunk_id': f"{document_id}_chunk_{len(chunks)}",
                        'document_id': document_id,
                        'user_id': user_id,
                        'text': text,
                        'type': 'paragraph',
                        'page_number': 1,  # TODO: í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
                        'bbox': None,
                        'metadata': {
                            'level': None,
                            'is_heading': text.startswith('#'),
                            'char_count': len(text)
                        }
                    })
            
            logger.info(f"   âœ“ Extracted {len(chunks)} text chunks")
            
        except Exception as e:
            logger.error(f"Text chunk extraction failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return chunks
    
    def _extract_tables(
        self,
        result,
        document_id: str,
        user_id: str
    ) -> List[Dict]:
        """í‘œ ì¶”ì¶œ (êµ¬ì¡°í™”ëœ ë°ì´í„°)"""
        tables = []
        
        try:
            # Docling 2.x: result.document.tables ë˜ëŠ” export_to_dict()
            if hasattr(result, 'document'):
                doc = result.document
                
                # í‘œ ì¶”ì¶œ ì‹œë„
                if hasattr(doc, 'tables'):
                    for i, table in enumerate(doc.tables):
                        table_data = self._parse_table_v2(table)
                        
                        if not table_data or not table_data.get('rows'):
                            continue
                        
                        searchable_text = self._table_to_text(table_data, "")
                        
                        tables.append({
                            'table_id': f"{document_id}_table_{len(tables)}",
                            'document_id': document_id,
                            'user_id': user_id,
                            'page_number': 1,  # TODO: í˜ì´ì§€ ë²ˆí˜¸
                            'bbox': None,
                            'caption': "",
                            'data': table_data,
                            'searchable_text': searchable_text,
                            'metadata': {
                                'num_rows': len(table_data.get('rows', [])),
                                'num_cols': len(table_data.get('headers', [])),
                                'has_caption': False
                            }
                        })
            
            logger.info(f"   âœ“ Extracted {len(tables)} tables")
            
        except Exception as e:
            logger.error(f"Table extraction failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return tables
    
    async def _extract_figures(
        self,
        result,
        document_id: str,
        user_id: str,
        original_file_path: str
    ) -> List[Dict]:
        """ê·¸ë¦¼/ì°¨íŠ¸ ì¶”ì¶œ (ColPali í†µí•©)"""
        figures = []
        
        try:
            # Docling 2.x: result.document.pictures ë˜ëŠ” images
            if hasattr(result, 'document'):
                doc = result.document
                
                # ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„
                if hasattr(doc, 'pictures'):
                    for i, picture in enumerate(doc.pictures):
                        figures.append({
                            'figure_id': f"{document_id}_figure_{len(figures)}",
                            'document_id': document_id,
                            'user_id': user_id,
                            'page_number': 1,  # TODO: í˜ì´ì§€ ë²ˆí˜¸
                            'bbox': None,
                            'caption': "",
                            'image_path': None,
                            'colpali_processed': False,
                            'colpali_patches': 0,
                            'metadata': {
                                'type': 'picture',
                                'has_caption': False
                            }
                        })
            
            logger.info(f"   âœ“ Extracted {len(figures)} figures")
            
        except Exception as e:
            logger.error(f"Figure extraction failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return figures
    
    def _parse_table_v2(self, table) -> Dict:
        """Docling 2.x í‘œ ë°ì´í„° íŒŒì‹±"""
        try:
            table_data = {'headers': [], 'rows': []}
            
            # í‘œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì‹±
            if hasattr(table, 'export_to_markdown'):
                md_text = table.export_to_markdown()
                lines = [l.strip() for l in md_text.split('\n') if l.strip() and not l.strip().startswith('|--')]
                
                if lines:
                    # ì²« ì¤„ì€ í—¤ë”
                    table_data['headers'] = [h.strip() for h in lines[0].split('|') if h.strip()]
                    # ë‚˜ë¨¸ì§€ëŠ” í–‰
                    table_data['rows'] = [
                        [cell.strip() for cell in line.split('|') if cell.strip()]
                        for line in lines[1:]
                    ]
            
            return table_data
            
        except Exception as e:
            logger.warning(f"Table v2 parsing failed: {e}")
            return {'headers': [], 'rows': []}
    
    def _parse_table(self, table_element) -> Dict:
        """í‘œ ë°ì´í„° íŒŒì‹±"""
        try:
            # Doclingì˜ í‘œ êµ¬ì¡° ì ‘ê·¼
            table_data = {'headers': [], 'rows': []}
            
            # í‘œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(table_element, 'data'):
                data = table_element.data
                
                # í—¤ë” ì¶”ì¶œ
                if hasattr(data, 'headers'):
                    table_data['headers'] = data.headers
                elif hasattr(data, 'header'):
                    table_data['headers'] = data.header
                
                # í–‰ ì¶”ì¶œ
                if hasattr(data, 'rows'):
                    table_data['rows'] = data.rows
                elif hasattr(data, 'body'):
                    table_data['rows'] = data.body
            
            # í…ìŠ¤íŠ¸ì—ì„œ íŒŒì‹± (fallback)
            elif hasattr(table_element, 'text'):
                lines = table_element.text.strip().split('\n')
                if lines:
                    table_data['headers'] = [h.strip() for h in lines[0].split('|')]
                    table_data['rows'] = [
                        [cell.strip() for cell in line.split('|')]
                        for line in lines[1:]
                    ]
            
            return table_data
            
        except Exception as e:
            logger.warning(f"Table parsing failed: {e}")
            return {'headers': [], 'rows': []}
    
    def _table_to_text(self, table_data: Dict, caption: str = "") -> str:
        """í‘œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = []
        
        # ìº¡ì…˜
        if caption:
            lines.append(f"Caption: {caption}")
        
        # í—¤ë”
        if table_data.get('headers'):
            lines.append(' | '.join(str(h) for h in table_data['headers']))
            lines.append('-' * 50)
        
        # í–‰
        for row in table_data.get('rows', []):
            lines.append(' | '.join(str(cell) for cell in row))
        
        return '\n'.join(lines)
    
    def _find_caption(self, page, element, element_type: str) -> str:
        """í‘œ/ê·¸ë¦¼ì˜ ìº¡ì…˜ ì°¾ê¸°"""
        try:
            element_bbox = self._get_bbox(element)
            if not element_bbox:
                return ""
            
            caption_candidates = []
            
            for other_element in page.elements:
                # ìº¡ì…˜ ë˜ëŠ” í…ìŠ¤íŠ¸ ìš”ì†Œ
                if other_element.type in ['caption', 'paragraph', 'text']:
                    text = getattr(other_element, 'text', '').strip()
                    
                    if not text:
                        continue
                    
                    # "í‘œ 1:", "Figure 2:" ë“±ì˜ íŒ¨í„´ í™•ì¸
                    is_caption = any(
                        keyword in text.lower()
                        for keyword in ['table', 'í‘œ', 'figure', 'ê·¸ë¦¼', 'chart', 'ì°¨íŠ¸']
                    )
                    
                    if is_caption or other_element.type == 'caption':
                        other_bbox = self._get_bbox(other_element)
                        if other_bbox:
                            distance = self._calculate_distance(element_bbox, other_bbox)
                            caption_candidates.append((distance, text))
            
            # ê°€ì¥ ê°€ê¹Œìš´ ìº¡ì…˜ ë°˜í™˜
            if caption_candidates:
                caption_candidates.sort(key=lambda x: x[0])
                return caption_candidates[0][1]
            
        except Exception as e:
            logger.warning(f"Caption finding failed: {e}")
        
        return ""
    
    def _get_bbox(self, element) -> Optional[List[float]]:
        """ìš”ì†Œì˜ bbox ê°€ì ¸ì˜¤ê¸°"""
        try:
            if hasattr(element, 'bbox'):
                bbox = element.bbox
                if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
                    return list(bbox)
            
            if hasattr(element, 'bounding_box'):
                bbox = element.bounding_box
                if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
                    return list(bbox)
        except:
            pass
        
        return None
    
    def _calculate_distance(self, bbox1: List[float], bbox2: List[float]) -> float:
        """ë‘ bbox ê°„ ê±°ë¦¬ ê³„ì‚°"""
        try:
            # ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬
            center1 = ((bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2)
            center2 = ((bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2)
            
            return ((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2) ** 0.5
        except:
            return float('inf')
    
    def _get_image_path(self, element, original_file_path: str, page_num: int) -> Optional[str]:
        """ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # Doclingì´ ì¶”ì¶œí•œ ì´ë¯¸ì§€ ê²½ë¡œ
            if hasattr(element, 'image_path'):
                return element.image_path
            
            if hasattr(element, 'image'):
                return element.image
            
            # Fallback: ì›ë³¸ íŒŒì¼ì—ì„œ ì¶”ì¶œ í•„ìš”
            # TODO: pdf2imageë¡œ í˜ì´ì§€ ì¶”ì¶œ
            
        except Exception as e:
            logger.warning(f"Image path extraction failed: {e}")
        
        return None
    
    async def _process_with_colpali(
        self,
        image_path: str,
        document_id: str,
        user_id: str,
        page_number: int,
        caption: str
    ) -> Optional[Dict]:
        """ColPalië¡œ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        try:
            # ì„ë² ë”© ìƒì„±
            result = self.colpali_processor.process_image(image_path)
            
            if result.get('embeddings') is None:
                return None
            
            # Milvus ì €ì¥
            await self.colpali_milvus.insert_image(
                image_path=image_path,
                embeddings=result['embeddings'],
                document_id=document_id,
                user_id=user_id,
                page_number=page_number,
                associated_text=caption[:5000] if caption else ""
            )
            
            logger.info(f"      âœ“ ColPali processed: {result.get('num_patches', 0)} patches")
            
            return result
            
        except Exception as e:
            logger.warning(f"ColPali processing failed: {e}")
            return None
    
    def _extract_layout(self, result) -> Dict:
        """ë ˆì´ì•„ì›ƒ ì •ë³´ ì¶”ì¶œ"""
        try:
            return {
                'num_pages': len(result.pages),
                'page_sizes': [
                    {
                        'width': getattr(page, 'width', 0),
                        'height': getattr(page, 'height', 0)
                    }
                    for page in result.pages
                ]
            }
        except:
            return {'num_pages': 0, 'page_sizes': []}
    
    def _extract_metadata(self, result) -> Dict:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            return {
                'title': getattr(result, 'title', ''),
                'author': getattr(result, 'author', ''),
                'creation_date': str(getattr(result, 'creation_date', '')),
                'num_pages': len(result.pages)
            }
        except:
            return {}
    
    def get_stats(self) -> Dict[str, Any]:
        """í”„ë¡œì„¸ì„œ í†µê³„"""
        return {
            'docling_available': self.converter is not None,
            'colpali_available': self.colpali_processor is not None,
            'enable_ocr': self.enable_ocr,
            'enable_table_structure': self.enable_table_structure,
            'enable_figure_extraction': self.enable_figure_extraction,
            'images_scale': self.images_scale
        }


# Global instance
_docling_processor: Optional[DoclingProcessor] = None


def get_docling_processor(
    enable_ocr: bool = True,
    enable_table_structure: bool = True,
    enable_figure_extraction: bool = True,
    images_scale: float = 2.0
) -> DoclingProcessor:
    """Get global Docling processor instance"""
    global _docling_processor
    
    if _docling_processor is None:
        _docling_processor = DoclingProcessor(
            enable_ocr=enable_ocr,
            enable_table_structure=enable_table_structure,
            enable_figure_extraction=enable_figure_extraction,
            images_scale=images_scale
        )
    
    return _docling_processor
