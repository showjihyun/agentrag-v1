"""
Hybrid Document Processor

ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ëÍ∑º Î∞©Ïãù:
1. Native ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (Îπ†Î¶Ñ, Ìö®Ïú®Ï†Å)
2. ColPali Ïù¥ÎØ∏ÏßÄ ÏûÑÎ≤†Îî© (Ï†ïÌôïÎèÑ, ÏãúÍ∞ÅÏ†Å Í≤ÄÏÉâ)
3. Í≤∞Í≥º Î≥ëÌï© Î∞è ÏµúÏ†ÅÌôî
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import asyncio

logger = logging.getLogger(__name__)


class HybridDocumentProcessor:
    """
    ÌïòÏù¥Î∏åÎ¶¨Îìú Î¨∏ÏÑú Ï≤òÎ¶¨Í∏∞
    
    Features:
    - Docling Í≥†Í∏â Î¨∏ÏÑú Ï≤òÎ¶¨ (Ìëú/Ï∞®Ìä∏ Ï∂îÏ∂ú)
    - Native ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (Fallback)
    - ColPali Ïù¥ÎØ∏ÏßÄ ÏûÑÎ≤†Îî© (ÏÑ†ÌÉùÏ†Å, Ï†ïÌôïÎèÑ)
    - Ïä§Ï∫îÎ≥∏ ÏûêÎèô Í∞êÏßÄ
    - ÎπÑÏö© ÏµúÏ†ÅÌôî
    """
    
    def __init__(
        self,
        use_docling: bool = True,  # NEW: Docling ÏÇ¨Ïö©
        enable_colpali: bool = True,
        colpali_threshold: float = 0.3,  # ÌÖçÏä§Ìä∏ ÎπÑÏú® ÏûÑÍ≥ÑÍ∞í
        process_images_always: bool = False  # Ìï≠ÏÉÅ Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨
    ):
        """
        Ï¥àÍ∏∞Ìôî
        
        Args:
            use_docling: Docling ÏÇ¨Ïö© Ïó¨Î∂Ä (Í∂åÏû•)
            enable_colpali: ColPali ÏÇ¨Ïö© Ïó¨Î∂Ä
            colpali_threshold: ÌÖçÏä§Ìä∏ ÎπÑÏú® ÏûÑÍ≥ÑÍ∞í (Ïù¥ÌïòÎ©¥ Ïä§Ï∫îÎ≥∏ÏúºÎ°ú ÌåêÎã®)
            process_images_always: Ìï≠ÏÉÅ Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ (ÌïòÏù¥Î∏åÎ¶¨Îìú Î™®Îìú)
        """
        self.use_docling = use_docling
        self.enable_colpali = enable_colpali
        self.colpali_threshold = colpali_threshold
        self.process_images_always = process_images_always
        
        # ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî
        self.docling_processor = None
        self.doc_processor = None
        self.colpali_processor = None
        self.colpali_milvus = None
        self.structured_data_service = None
        
        self._init_processors()
        
        logger.info(
            f"HybridDocumentProcessor initialized: "
            f"docling={use_docling}, "
            f"colpali={enable_colpali}, "
            f"threshold={colpali_threshold}, "
            f"always_process={process_images_always}"
        )
    
    def _init_processors(self):
        """ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî"""
        try:
            # Docling ÌîÑÎ°úÏÑ∏ÏÑú (Ïö∞ÏÑ†)
            if self.use_docling:
                try:
                    from backend.services.docling_processor import get_docling_processor
                    from backend.services.structured_data_service import get_structured_data_service
                    
                    self.docling_processor = get_docling_processor(
                        enable_ocr=True,
                        enable_table_structure=True,
                        enable_figure_extraction=True,
                        images_scale=2.0
                    )
                    self.structured_data_service = get_structured_data_service()
                    
                    logger.info("‚úÖ Docling processor initialized")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Docling not available: {e}")
                    logger.warning("Falling back to native processor")
                    self.use_docling = False
            
            # Native ÌÖçÏä§Ìä∏ ÌîÑÎ°úÏÑ∏ÏÑú (Fallback)
            if not self.use_docling:
                from backend.services.document_processor import DocumentProcessor
                self.doc_processor = DocumentProcessor()
                logger.info("‚úÖ Native document processor initialized")
            
            # ColPali ÌîÑÎ°úÏÑ∏ÏÑú (ÏÑ†ÌÉùÏ†Å)
            if self.enable_colpali:
                try:
                    from backend.services.colpali_processor import get_colpali_processor
                    from backend.services.colpali_milvus_service import get_colpali_milvus_service
                    from backend.config import settings
                    
                    self.colpali_processor = get_colpali_processor(
                        model_name=settings.COLPALI_MODEL,
                        use_gpu=settings.COLPALI_USE_GPU,
                        enable_binarization=settings.COLPALI_ENABLE_BINARIZATION,
                        enable_pooling=settings.COLPALI_ENABLE_POOLING,
                        pooling_factor=settings.COLPALI_POOLING_FACTOR
                    )
                    self.colpali_milvus = get_colpali_milvus_service()
                    
                    if self.colpali_processor:
                        model_info = self.colpali_processor.get_model_info()
                        logger.info(f"‚úÖ ColPali processor initialized on {model_info['device']}")
                    else:
                        logger.warning("‚ö†Ô∏è  ColPali processor returned None")
                        self.enable_colpali = False
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  ColPali not available: {e}")
                    self.enable_colpali = False
            
        except Exception as e:
            logger.error(f"Failed to initialize processors: {e}")
            raise
    
    async def process_document(
        self,
        file_path: str,
        file_type: str,
        document_id: str,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ÌïòÏù¥Î∏åÎ¶¨Îìú Î¨∏ÏÑú Ï≤òÎ¶¨
        
        Args:
            file_path: ÌååÏùº Í≤ΩÎ°ú
            file_type: ÌååÏùº ÌÉÄÏûÖ
            document_id: Î¨∏ÏÑú ID
            metadata: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
        
        Returns:
            Ï≤òÎ¶¨ Í≤∞Í≥º
        """
        # Docling ÏÇ¨Ïö© Ïãú
        if self.use_docling and self.docling_processor:
            return await self._process_with_docling(
                file_path, file_type, document_id, metadata
            )
        
        # Legacy Ï≤òÎ¶¨
        return await self._process_legacy(
            file_path, file_type, document_id, metadata
        )
    
    async def _process_with_docling(
        self,
        file_path: str,
        file_type: str,
        document_id: str,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """DoclingÏùÑ ÏÇ¨Ïö©Ìïú Î¨∏ÏÑú Ï≤òÎ¶¨"""
        try:
            logger.info(f"üöÄ Processing with Docling: {document_id}")
            
            # ÏÇ¨Ïö©Ïûê ID Ï∂îÏ∂ú
            user_id = (metadata or {}).get('user_id', 'unknown')
            
            # Docling Ï≤òÎ¶¨
            docling_result = await self.docling_processor.process_document(
                file_path=file_path,
                document_id=document_id,
                user_id=user_id,
                metadata=metadata
            )
            
            # Ìëú Îç∞Ïù¥ÌÑ∞Î•º MilvusÏóê Ï†ÄÏû•
            if self.structured_data_service and docling_result.get('tables'):
                logger.info(f"üíæ Saving {len(docling_result['tables'])} tables to Milvus...")
                for table in docling_result['tables']:
                    try:
                        self.structured_data_service.insert_table(
                            table_id=table['table_id'],
                            document_id=table['document_id'],
                            user_id=table['user_id'],
                            page_number=table['page_number'],
                            caption=table['caption'],
                            searchable_text=table['searchable_text'],
                            table_data=table['data'],
                            bbox=table.get('bbox'),
                            metadata=table.get('metadata')
                        )
                    except Exception as e:
                        logger.error(f"Failed to save table {table['table_id']}: {e}")
            
            # Í≤∞Í≥º Î≥ÄÌôò (Í∏∞Ï°¥ ÌòïÏãùÍ≥º Ìò∏Ìôò)
            result = {
                'document_id': document_id,
                'file_type': file_type,
                'processing_method': 'docling',
                'native_text': self._combine_text_chunks(docling_result.get('text_chunks', [])),
                'native_chunks': docling_result.get('text_chunks', []),
                'tables': docling_result.get('tables', []),
                'figures': docling_result.get('figures', []),
                'colpali_processed': any(
                    fig.get('colpali_processed', False)
                    for fig in docling_result.get('figures', [])
                ),
                'colpali_patches': sum(
                    fig.get('colpali_patches', 0)
                    for fig in docling_result.get('figures', [])
                ),
                'layout': docling_result.get('layout', {}),
                'metadata': docling_result.get('metadata', {}),
                'stats': docling_result.get('stats', {})
            }
            
            logger.info(
                f"‚úÖ Docling processing complete: "
                f"{result['stats'].get('num_text_chunks', 0)} chunks, "
                f"{result['stats'].get('num_tables', 0)} tables, "
                f"{result['stats'].get('num_figures', 0)} figures"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Docling processing failed: {e}")
            logger.warning("Falling back to legacy processing")
            return await self._process_legacy(file_path, file_type, document_id, metadata)
    
    def _combine_text_chunks(self, chunks: List[Dict]) -> str:
        """ÌÖçÏä§Ìä∏ Ï≤≠ÌÅ¨Î•º ÌïòÎÇòÏùò Î¨∏ÏûêÏó¥Î°ú Í≤∞Ìï©"""
        return '\n\n'.join(chunk.get('text', '') for chunk in chunks)
    
    async def _process_legacy(
        self,
        file_path: str,
        file_type: str,
        document_id: str,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Legacy Î¨∏ÏÑú Ï≤òÎ¶¨ (Í∏∞Ï°¥ Î∞©Ïãù)"""
        result = {
            'document_id': document_id,
            'file_type': file_type,
            'native_text': None,
            'native_chunks': [],
            'colpali_processed': False,
            'colpali_patches': 0,
            'is_scanned': False,
            'processing_method': None,
            'text_ratio': 0.0
        }
        
        try:
            # 1Îã®Í≥Ñ: Native ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (Ìï≠ÏÉÅ ÏãúÎèÑ)
            logger.info(f"Step 1: Native text extraction for {document_id}")
            
            with open(file_path, 'rb') as f:
                file_content = f.read()
            
            native_text = self.doc_processor.extract_text(file_content, file_type)
            result['native_text'] = native_text
            
            # ÌÖçÏä§Ìä∏ ÌíàÏßà Î∂ÑÏÑù
            text_ratio = self._analyze_text_quality(native_text, file_content)
            result['text_ratio'] = text_ratio
            
            logger.info(
                f"Native text extracted: {len(native_text)} chars, "
                f"text_ratio={text_ratio:.2f}"
            )
            
            # 2Îã®Í≥Ñ: Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÌòïÏãù ÌôïÏù∏
            image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.tiff'}
            file_ext = Path(file_path).suffix.lower()
            is_image_file = file_ext in image_extensions
            
            logger.info(f"üìÑ File analysis: ext={file_ext}, is_image={is_image_file}")
            
            # 2.5Îã®Í≥Ñ: Ïä§Ï∫îÎ≥∏ Ïó¨Î∂Ä ÌåêÎã®
            is_scanned = text_ratio < self.colpali_threshold
            result['is_scanned'] = is_scanned
            
            if is_scanned:
                logger.info(f"üìã Document {document_id} detected as scanned (text_ratio={text_ratio:.2f})")
            
            if is_image_file:
                logger.info(f"üñºÔ∏è  Document {document_id} is an image file ({file_ext})")
            
            # 3Îã®Í≥Ñ: ColPali Ï≤òÎ¶¨ Í≤∞Ï†ï
            should_use_colpali = False
            
            logger.info(f"üîç ColPali check: enabled={self.enable_colpali}, processor_available={self.colpali_processor is not None}")
            
            if self.enable_colpali and self.colpali_processor:
                # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏù¥Î©¥ Î¨¥Ï°∞Í±¥ ColPali Ï≤òÎ¶¨
                if is_image_file:
                    should_use_colpali = True
                    result['processing_method'] = 'colpali_only'
                    logger.info("‚úÖ Using ColPali (image file)")
                    
                elif is_scanned:
                    # Ïä§Ï∫îÎ≥∏Ïù¥Î©¥ ColPali ÌïÑÏàò
                    should_use_colpali = True
                    result['processing_method'] = 'colpali_only'
                    logger.info("‚úÖ Using ColPali (scanned document)")
                    
                elif self.process_images_always:
                    # ÌïòÏù¥Î∏åÎ¶¨Îìú Î™®Îìú: Îëò Îã§ ÏÇ¨Ïö©
                    should_use_colpali = True
                    result['processing_method'] = 'hybrid'
                    logger.info("‚úÖ Using Hybrid (Native + ColPali)")
                    
                else:
                    # NativeÎßå ÏÇ¨Ïö©
                    result['processing_method'] = 'native_only'
                    logger.info("‚ÑπÔ∏è  Using Native only (good text quality)")
            else:
                result['processing_method'] = 'native_only'
                logger.warning("‚ö†Ô∏è  ColPali not available - using Native only")
            
            # 4Îã®Í≥Ñ: ColPali Ï≤òÎ¶¨ (ÌïÑÏöîÏãú)
            if should_use_colpali:
                logger.info(f"üöÄ Step 2: ColPali processing for {document_id}")
                
                try:
                    # PDFÎ•º Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôò (ÌïÑÏöîÏãú)
                    if file_type == 'pdf':
                        logger.info(f"üìÑ Converting PDF to images...")
                        image_paths = await self._pdf_to_images(file_path)
                    else:
                        # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÄ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
                        image_paths = [file_path]
                        logger.info(f"üñºÔ∏è  Using image file directly: {file_path}")
                    
                    # ColPaliÎ°ú Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨
                    total_patches = 0
                    for i, img_path in enumerate(image_paths, 1):
                        logger.info(f"üîÑ Processing image {i}/{len(image_paths)}: {Path(img_path).name}")
                        colpali_result = self.colpali_processor.process_image(img_path)
                        
                        # MilvusÏóê Ï†ÄÏû•
                        if colpali_result.get('embeddings') is not None:
                            # Extract user_id from metadata
                            user_id = (metadata or {}).get('user_id', 'unknown')
                            
                            # Phase 2: Extract associated text
                            # For images, use native_text as context
                            # For PDFs, could extract text from same page
                            associated_text = native_text[:5000] if native_text else ""
                            
                            # Extract page number if available
                            page_number = (metadata or {}).get('page_number', i)
                            
                            await self.colpali_milvus.insert_image(
                                image_path=img_path,
                                embeddings=colpali_result['embeddings'],
                                document_id=document_id,
                                user_id=user_id,
                                metadata={
                                    'file_type': file_type,
                                    'is_scanned': is_scanned,
                                    'text_ratio': text_ratio,
                                    'image_index': i,
                                    **(metadata or {})
                                },
                                page_number=page_number,  # Phase 2
                                associated_text=associated_text  # Phase 2
                            )
                            patches = colpali_result.get('num_patches', 0)
                            total_patches += patches
                            logger.info(f"   ‚úì Saved {patches} patches to Milvus")
                    
                    result['colpali_processed'] = True
                    result['colpali_patches'] = total_patches
                    
                    logger.info(
                        f"‚úÖ ColPali processing completed: {total_patches} patches"
                    )
                    
                except Exception as e:
                    logger.error(f"ColPali processing failed: {e}")
                    # ColPali Ïã§Ìå®Ìï¥ÎèÑ Native ÌÖçÏä§Ìä∏Îäî ÏÇ¨Ïö© Í∞ÄÎä•
            
            # 5Îã®Í≥Ñ: ÌÖçÏä§Ìä∏ Ï≤≠ÌÇπ (Native ÌÖçÏä§Ìä∏)
            if native_text and native_text.strip():
                chunks = self.doc_processor.chunk_text(native_text, document_id)
                result['native_chunks'] = chunks
                logger.info(f"Created {len(chunks)} chunks from native text")
            
            return result
            
        except Exception as e:
            logger.error(f"Hybrid document processing failed: {e}")
            raise
    
    def _analyze_text_quality(self, text: str, file_content: bytes) -> float:
        """
        ÌÖçÏä§Ìä∏ ÌíàÏßà Î∂ÑÏÑù (Ïä§Ï∫îÎ≥∏ Í∞êÏßÄ)
        
        Args:
            text: Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏
            file_content: ÏõêÎ≥∏ ÌååÏùº ÎÇ¥Ïö©
        
        Returns:
            ÌÖçÏä§Ìä∏ ÎπÑÏú® (0.0 ~ 1.0)
        """
        if not text or not text.strip():
            return 0.0
        
        # ÌÖçÏä§Ìä∏ Í∏∏Ïù¥ ÎåÄÎπÑ ÌååÏùº ÌÅ¨Í∏∞ ÎπÑÏú®
        text_bytes = len(text.encode('utf-8'))
        file_bytes = len(file_content)
        
        if file_bytes == 0:
            return 0.0
        
        # ÎπÑÏú® Í≥ÑÏÇ∞ (Ï†ïÍ∑úÌôî)
        ratio = min(text_bytes / file_bytes, 1.0)
        
        # Ï∂îÍ∞Ä Ìú¥Î¶¨Ïä§Ìã±
        # - ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ ÏßßÏúºÎ©¥ Ïä§Ï∫îÎ≥∏Ïùº Í∞ÄÎä•ÏÑ±
        if len(text.strip()) < 100:
            ratio *= 0.5
        
        # - ÌäπÏàòÎ¨∏Ïûê/Í≥µÎ∞±Ïù¥ ÎÑàÎ¨¥ ÎßéÏúºÎ©¥ OCR Ïò§Î•òÏùº Í∞ÄÎä•ÏÑ±
        special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())
        if len(text) > 0 and special_chars / len(text) > 0.3:
            ratio *= 0.7
        
        return ratio
    
    async def _pdf_to_images(self, pdf_path: str) -> List[str]:
        """
        PDFÎ•º Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôò
        
        Args:
            pdf_path: PDF ÌååÏùº Í≤ΩÎ°ú
        
        Returns:
            Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú Î¶¨Ïä§Ìä∏
        """
        try:
            from pdf2image import convert_from_path
            import tempfile
            import os
            
            # PDFÎ•º Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôò
            images = convert_from_path(pdf_path, dpi=200)
            
            # ÏûÑÏãú ÌååÏùºÎ°ú Ï†ÄÏû•
            image_paths = []
            temp_dir = tempfile.mkdtemp()
            
            for i, image in enumerate(images):
                img_path = os.path.join(temp_dir, f"page_{i+1}.png")
                image.save(img_path, 'PNG')
                image_paths.append(img_path)
            
            logger.info(f"Converted PDF to {len(image_paths)} images")
            return image_paths
            
        except ImportError:
            logger.warning("pdf2image not available, using PDF as-is")
            return [pdf_path]
        except Exception as e:
            logger.error(f"PDF to image conversion failed: {e}")
            return [pdf_path]
    
    def get_stats(self) -> Dict[str, Any]:
        """ÌÜµÍ≥Ñ Î∞òÌôò"""
        return {
            'use_docling': self.use_docling,
            'docling_available': self.docling_processor is not None,
            'enable_colpali': self.enable_colpali,
            'colpali_threshold': self.colpali_threshold,
            'process_images_always': self.process_images_always,
            'colpali_available': self.colpali_processor is not None,
            'structured_data_available': self.structured_data_service is not None
        }


# Global instance
_hybrid_processor: Optional[HybridDocumentProcessor] = None


def get_hybrid_document_processor(
    use_docling: bool = True,
    enable_colpali: bool = True,
    colpali_threshold: float = 0.3,
    process_images_always: bool = False
) -> HybridDocumentProcessor:
    """Get global hybrid document processor instance"""
    global _hybrid_processor
    
    if _hybrid_processor is None:
        _hybrid_processor = HybridDocumentProcessor(
            use_docling=use_docling,
            enable_colpali=enable_colpali,
            colpali_threshold=colpali_threshold,
            process_images_always=process_images_always
        )
    
    return _hybrid_processor
