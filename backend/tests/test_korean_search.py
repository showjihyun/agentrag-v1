"""
í•œê¸€ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
- ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ (í•œê¸€ ì§€ì›)
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)
- í•œê¸€ í† í¬ë‚˜ì´ì €
- ë‹¤ì–‘í•œ í•œê¸€ ì¿¼ë¦¬ íŒ¨í„´
"""

import asyncio
import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from backend.services.hybrid_search import HybridSearchManager
from backend.services.milvus import MilvusManager
from backend.services.embedding import EmbeddingService
from backend.config import settings


async def test_korean_search():
    """í•œê¸€ ê²€ìƒ‰ ê¸°ëŠ¥ ì¢…í•© í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 80)
    print("ğŸ‡°ğŸ‡· í•œê¸€ ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # 1. ì´ˆê¸°í™”
    print("\n[1/5] ğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    try:
        embedding_service = EmbeddingService(model_name=settings.EMBEDDING_MODEL)
        print(f"   âœ… ì„ë² ë”© ëª¨ë¸: {embedding_service.model_name}")
        print(f"   âœ… ì„ë² ë”© ì°¨ì›: {embedding_service.dimension}")
        print(f"   âœ… ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {embedding_service.model.max_seq_length}")
    except Exception as e:
        print(f"   âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # 2. í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¤€ë¹„
    print("\n[2/5] ğŸ“š í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¤€ë¹„ ì¤‘...")
    test_documents = [
        {
            "id": "test_1",
            "document_id": "doc_ai",
            "text": "ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. "
            "ê¸°ê³„í•™ìŠµ, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. "
            "AIëŠ” ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.",
            "document_name": "AI_ê¸°ì´ˆ.txt",
            "chunk_index": 0,
            "file_type": "txt",
            "upload_date": 1704441600,
        },
        {
            "id": "test_2",
            "document_id": "doc_ml",
            "text": "ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” AIì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤. "
            "ì§€ë„í•™ìŠµ, ë¹„ì§€ë„í•™ìŠµ, ê°•í™”í•™ìŠµìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. "
            "ê¸°ê³„í•™ìŠµì´ë¼ê³ ë„ ë¶ˆë¦¬ë©°, ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.",
            "document_name": "ML_ê°€ì´ë“œ.txt",
            "chunk_index": 0,
            "file_type": "txt",
            "upload_date": 1704441600,
        },
        {
            "id": "test_3",
            "document_id": "doc_dl",
            "text": "ë”¥ëŸ¬ë‹ì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤. "
            "CNN, RNN, Transformer ë“±ì˜ ì•„í‚¤í…ì²˜ê°€ ìˆìŠµë‹ˆë‹¤. "
            "ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.",
            "document_name": "ë”¥ëŸ¬ë‹_ê°€ì´ë“œ.txt",
            "chunk_index": 0,
            "file_type": "txt",
            "upload_date": 1704441600,
        },
        {
            "id": "test_4",
            "document_id": "doc_nlp",
            "text": "ìì—°ì–´ ì²˜ë¦¬(NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. "
            "ê¸°ê³„ ë²ˆì—­, í…ìŠ¤íŠ¸ ìš”ì•½, ê°ì • ë¶„ì„, ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ ë“±ì— í™œìš©ë©ë‹ˆë‹¤. "
            "GPT, BERT ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ NLP ë°œì „ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.",
            "document_name": "NLP_ì†Œê°œ.txt",
            "chunk_index": 0,
            "file_type": "txt",
            "upload_date": 1704441600,
        },
        {
            "id": "test_5",
            "document_id": "doc_cv",
            "text": "ì»´í“¨í„° ë¹„ì „ì€ ì»´í“¨í„°ê°€ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. "
            "ê°ì²´ ê°ì§€, ì´ë¯¸ì§€ ë¶„ë¥˜, ì–¼êµ´ ì¸ì‹, ììœ¨ì£¼í–‰ ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤. "
            "CNN ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì»´í“¨í„° ë¹„ì „ì˜ í•µì‹¬ì…ë‹ˆë‹¤.",
            "document_name": "CV_ê°œìš”.txt",
            "chunk_index": 0,
            "file_type": "txt",
            "upload_date": 1704441600,
        },
    ]
    print(f"   âœ… {len(test_documents)}ê°œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ")

    # 3. Milvus ì—°ê²° ë° ë¬¸ì„œ ì‚½ì…
    print("\n[3/5] ğŸ—„ï¸  Milvus ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
    try:
        milvus_manager = MilvusManager(
            host=settings.MILVUS_HOST,
            port=settings.MILVUS_PORT,
            collection_name="test_korean_search",
            embedding_dim=embedding_service.dimension,
        )
        milvus_manager.connect()
        print(f"   âœ… Milvus ì—°ê²° ì„±ê³µ: {settings.MILVUS_HOST}:{settings.MILVUS_PORT}")

        # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ì‚­ì œ ë° ì¬ìƒì„±
        milvus_manager.create_collection(drop_existing=True)
        print("   âœ… í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")

        # ì„ë² ë”© ìƒì„± ë° ì‚½ì…
        texts = [doc["text"] for doc in test_documents]
        embeddings = embedding_service.embed_batch(texts)
        await milvus_manager.insert_embeddings(embeddings, test_documents)
        print(f"   âœ… {len(test_documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ë° ì‚½ì… ì™„ë£Œ")

    except Exception as e:
        print(f"   âŒ Milvus ì„¤ì • ì‹¤íŒ¨: {e}")
        return

    # 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì´ˆê¸°í™”
    print("\n[4/5] ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    try:
        hybrid_search = HybridSearchManager(
            milvus_manager=milvus_manager,
            embedding_service=embedding_service,
            vector_weight=settings.VECTOR_SEARCH_WEIGHT,
            keyword_weight=settings.KEYWORD_SEARCH_WEIGHT,
        )
        hybrid_search.build_bm25_index(test_documents)
        print("   âœ… BM25 í‚¤ì›Œë“œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")
        print(
            f"   âœ… ê²€ìƒ‰ ê°€ì¤‘ì¹˜: ë²¡í„°={settings.VECTOR_SEARCH_WEIGHT}, í‚¤ì›Œë“œ={settings.KEYWORD_SEARCH_WEIGHT}"
        )
    except Exception as e:
        print(f"   âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        milvus_manager.disconnect()
        return

    # 5. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
    print("\n[5/5] ğŸ§ª í•œê¸€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print("=" * 80)

    test_cases = [
        {
            "query": "ì¸ê³µì§€ëŠ¥ì´ë€?",
            "description": "ê¸°ë³¸ í•œê¸€ ê²€ìƒ‰",
            "expected": "AI_ê¸°ì´ˆ.txt",
        },
        {
            "query": "AI ê¸°ìˆ ",
            "description": "í•œì˜ í˜¼í•© ê²€ìƒ‰",
            "expected": "AI_ê¸°ì´ˆ.txt",
        },
        {
            "query": "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´",
            "description": "ë³µí•© ì§ˆë¬¸",
            "expected": "ML_ê°€ì´ë“œ.txt",
        },
        {
            "query": "ìì—°ì–´ì²˜ë¦¬",
            "description": "ë„ì–´ì“°ê¸° ì—†ëŠ” ê²€ìƒ‰",
            "expected": "NLP_ì†Œê°œ.txt",
        },
        {
            "query": "ê¸°ê³„í•™ìŠµ ë°©ë²•",
            "description": "ë™ì˜ì–´ ê²€ìƒ‰ (ë¨¸ì‹ ëŸ¬ë‹=ê¸°ê³„í•™ìŠµ)",
            "expected": "ML_ê°€ì´ë“œ.txt",
        },
        {
            "query": "ì´ë¯¸ì§€ ì¸ì‹ ê¸°ìˆ ",
            "description": "ê´€ë ¨ ê°œë… ê²€ìƒ‰",
            "expected": "CV_ê°œìš”.txt",
        },
        {
            "query": "GPT BERT ëª¨ë¸",
            "description": "ì˜ì–´ ì•½ì–´ ê²€ìƒ‰",
            "expected": "NLP_ì†Œê°œ.txt",
        },
    ]

    passed = 0
    failed = 0

    for i, test_case in enumerate(test_cases, 1):
        query = test_case["query"]
        description = test_case["description"]
        expected = test_case["expected"]

        print(f"\ní…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}: {description}")
        print(f"ì¿¼ë¦¬: '{query}'")
        print("-" * 80)

        try:
            results = await hybrid_search.hybrid_search(query=query, top_k=3)

            if results:
                print(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")

                # ì²« ë²ˆì§¸ ê²°ê³¼ í™•ì¸
                top_result = results[0]
                is_correct = expected in top_result["document_name"]

                for j, result in enumerate(results, 1):
                    marker = "ğŸ¯" if j == 1 and is_correct else "  "
                    print(f"\n{marker} [{j}] ì ìˆ˜: {result['combined_score']:.4f}")
                    print(f"      ë¬¸ì„œ: {result['document_name']}")
                    print(f"      ë‚´ìš©: {result['text'][:70]}...")
                    print(
                        f"      ìƒì„¸: ë²¡í„°={result['vector_score']:.3f}, í‚¤ì›Œë“œ={result['bm25_score']:.3f}"
                    )

                if is_correct:
                    print(f"\nâœ… í…ŒìŠ¤íŠ¸ í†µê³¼: ì˜ˆìƒ ë¬¸ì„œ '{expected}' ë°œê²¬")
                    passed += 1
                else:
                    print(f"\nâš ï¸  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ì˜ˆìƒ ë¬¸ì„œ '{expected}' ë¯¸ë°œê²¬")
                    failed += 1
            else:
                print("âŒ ê²°ê³¼ ì—†ìŒ")
                failed += 1

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            failed += 1

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"ì´ í…ŒìŠ¤íŠ¸: {len(test_cases)}ê°œ")
    print(f"âœ… í†µê³¼: {passed}ê°œ ({passed/len(test_cases)*100:.1f}%)")
    print(f"âŒ ì‹¤íŒ¨: {failed}ê°œ ({failed/len(test_cases)*100:.1f}%)")

    if passed == len(test_cases):
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! í•œê¸€ ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    elif passed >= len(test_cases) * 0.7:
        print("\nâœ… ëŒ€ë¶€ë¶„ì˜ í…ŒìŠ¤íŠ¸ í†µê³¼. ì‹œìŠ¤í…œì´ ì˜ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    print("=" * 80)

    # ì •ë¦¬
    print("\nğŸ§¹ ì •ë¦¬ ì¤‘...")
    milvus_manager.disconnect()
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    try:
        asyncio.run(test_korean_search())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\n\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
